---
layout: post
title: "mov转gif"
---



# mov转gif 

源码来自： 
[LivePhotoToAnimatedGif](https://github.com/itok/LivePhotoToAnimatedGif)

视频转gif其实应该是很容易的事，因为都是一帧一帧的图片（？


在尝试做这件事之前，首先需要明白几件事： 

- CMTime， CMTime是一个struct. 看它的API.

```
/*!
	@typedef	CMTime
	@abstract	Rational time value represented as int64/int32.
*/
public struct CMTime {

    
    public var value: CMTimeValue /*! @field value The value of the CMTime. value/timescale = seconds. */

    /*! @field value The value of the CMTime. value/timescale = seconds. */
    public var timescale: CMTimeScale /*! @field timescale The timescale of the CMTime. value/timescale = seconds.  */

    /*! @field timescale The timescale of the CMTime. value/timescale = seconds.  */
    public var flags: CMTimeFlags /*! @field flags The flags, eg. kCMTimeFlags_Valid, kCMTimeFlags_PositiveInfinity, etc. */

    /*! @field flags The flags, eg. kCMTimeFlags_Valid, kCMTimeFlags_PositiveInfinity, etc. */
    public var epoch: CMTimeEpoch /*! @field epoch Differentiates between equal timestamps that are actually different because
												 of looping, multi-item sequencing, etc.  
												 Will be used during comparison: greater epochs happen after lesser ones. 
												 Additions/subtraction is only possible within a single epoch,
												 however, since epoch length may be unknown/variable. */

    public init()

    public init(value: CMTimeValue, timescale: CMTimeScale, flags: CMTimeFlags, epoch: CMTimeEpoch)
}
```

对于一个AVAsset，我们就可以直接 movieAsset.duration 得到的就是CMTime这个结构。

需要注意的是这个value并不是视频时长，真正的视频时长是 → `value/timescale = seconds` 或者 `CMTimeGetSeconds(movieAsset.duration)`.



### 生成时间

```
// gif frames
let numFrame = 30
let frameValue = movieAsset.duration.value / Int64(numFrame)
let timeScale = movieAsset.duration.timescale
var times = Array<NSValue>()
for i in 0..<numFrame {
	let time = CMTimeMakeWithEpoch(frameValue * Int64(i), timeScale, movieAsset.duration.epoch)
	times.append(NSValue(CMTime: time))
}
```

规定这个gif一共30帧，然后得到frameValue，这个应该算frame间隔时间，然后这一串时间其实应当是我们需要取出来的那一帧的时间（？

### 保存gif

```
guard let docDir = NSSearchPathForDirectoriesInDomains(.DocumentDirectory, .UserDomainMask, true).first else {
	return
}
let gifPath = (docDir as NSString).stringByAppendingPathComponent((resource.originalFilename as NSString).stringByDeletingPathExtension + ".gif")
let gifURL = NSURL(fileURLWithPath: gifPath)

guard let gif = CGImageDestinationCreateWithURL(gifURL, kUTTypeGIF, numFrame, nil) else {
	return
}
``` 

然后我们非常快的就保存gif了，前面部分获得路径，生成path，生成url，保存url，然后给的参数可以值得注意， 地址， 类型，numFrame, nil


### 真正的生成才出现


```
let delay = CMTimeGetSeconds(movieAsset.duration) / Float64(numFrame)
let frameProperty = [String(kCGImagePropertyGIFDictionary): [String(kCGImagePropertyGIFDelayTime): delay]]
	
var cnt = 0
// generate thumbnails and write to gif
let generator = AVAssetImageGenerator(asset: movieAsset)
// generate in any timelines
generator.requestedTimeToleranceBefore = kCMTimeZero
generator.requestedTimeToleranceAfter = kCMTimeZero
// apply video transform
generator.appliesPreferredTrackTransform = true
generator.maximumSize = CGSizeMake(640, 640)
generator.generateCGImagesAsynchronouslyForTimes(times) { (requested, image, actual, result, err) -> Void in
	if let image = image {
		CGImageDestinationAddImage(gif, image, frameProperty)
	}
	cnt += 1
	if cnt >= numFrame {
		let gifProperty = [String(kCGImagePropertyGIFDictionary): [String(kCGImagePropertyGIFLoopCount): 0]]
		CGImageDestinationSetProperties(gif, gifProperty)
		CGImageDestinationFinalize(gif)
		
		dispatch_async(dispatch_get_main_queue(), { () -> Void in
			self.webView.loadRequest(NSURLRequest(URL: gifURL))
		})
	}
	}
}
```

这里的delay算的是视频我们取得帧与真之间的时间间隔，然后根据这个时间我们来配置了一下gif的属性。

>kCGImagePropertyGIFDelayTime : 
The amount of time, in seconds, to wait before displaying the next image in an animated sequence.


然后我们使用AVAssetImageGenerator来取视频里面的帧
> AVAssetImageGenerator: 
An AVAssetImageGenerator object provides thumbnail or preview images of assets independently of playback.

```
generator.requestedTimeToleranceBefore = kCMTimeZero
generator.requestedTimeToleranceAfter = kCMTimeZero
```

这两句就是用来取exact那一帧的。


> appliesPreferredTrackTransform : 
Specifies whether to apply the track matrix (or matrices) when extracting an image from the asset.

因为我们生成的size是改变的，所以我们用了这个，并且设置了maximumSize


下面的是\*重中之重Core\*部分

>generateCGImagesAsynchronously(forTimes:completionHandler:) : 
Creates a series of CGImage objects for an asset at or near specified times.

我们把取得的image添加到gif中，并且把cnt增加，当我们已经添加了与要求的帧数一样的视频之后，我们再来设定这个gif的一些property，我发现把这个设置成1或者0生成的文件用diff查看都是一样的嘛。

> kCGImagePropertyGIFLoopCount:
The number of times to repeat an animated sequence.


到此，gif生成结束，用webView来加载显示，（当然我可以用自己写的更好的UIImage的ExtensionO(∩_∩)O~）

[kcgimagepropertygifdelaytime](https://developer.apple.com/reference/imageio/kcgimagepropertygifdelaytime)

[GIF Dictionary Keys](https://developer.apple.com/reference/imageio/cgimageproperties/gif_dictionary_keys)

[AVAssetImageGenerator](https://developer.apple.com/reference/avfoundation/avassetimagegenerator)

[appliesPreferredTrackTransform](https://developer.apple.com/reference/avfoundation/avassetimagegenerator/1390616-appliespreferredtracktransform)

[maximumsize](https://developer.apple.com/reference/avfoundation/avassetimagegenerator/1387560-maximumsize)

[kcgimagepropertygifloopcount](https://developer.apple.com/reference/imageio/kcgimagepropertygifloopcount)


